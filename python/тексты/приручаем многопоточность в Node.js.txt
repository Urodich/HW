Продолжаем серию статей, посвященных разным прикладным концептуальным решениям, которые могут существенно "прокачать" производительность вашего Node.js-приложения.

В прошлой статье мы рассмотрели реализацию эффективной очереди на основе "эластичного" кольцевого буфера, а в этой попробуем разобраться с особенностями использования модуля Worker threads в Node.js - какие проблемы внедрения многопоточности будут нас ждать при попытках сделать код более производительным, и узнаем, как их можно обойти, применяя типовые концепты.

Начнем с достаточно типовой задачи: мы получаем некоторые сообщения, и нам их надо как-то обработать. В качестве тестового примера сгенерируем эти сообщения самостоятельно, и посмотрим, за какое минимальное время мы сможем вычислить SHA-256-хэш для каждого из них.

Возьмем совсем простой пример: 4096 случайно сгенерированных "сообщения" объемом 64KB каждое (все программисты любят красивые числа) прохэшируем прямо в основном потоке:
Вспомогательный поток
Обычно первая попытка внедрения многопоточности начинается с "я слышал, что CPU-нагруженные задачи можно эффективно распараллелить с помощью потоков!"

Конечно, полностью цитата из документации выглядит чуть иначе:

Workers (threads) are useful for performing CPU-intensive JavaScript operations. They do not help much with I/O-intensive work. The Node.js built-in asynchronous I/O operations are more efficient than Workers can be.

В том смысле, что для CPU-нагруженных задач потоки могут помочь (а могут ведь и не помочь, поскольку вовсе не обязаны), а для I/O-нагруженных можете даже и не пытаться.

Но у нас-то как раз в чистом виде CPU-intensive, так что мы все-таки попытаемся. И начнем с элементарного, срисованного с мануала, варианта с одним вспомогательным потоком:
Тут мы знакомимся с первыми концептами:

если вам необходимо как-то увязать переданную в поток задачу и ответ на нее, то передача связующего ID туда-обратно - на вашей совести.

все асинхронно, поэтому нет понятия порядка операций, откуда следует, что ...

вам необходимо считать количество ответов, чтобы узнать, когда наступит момент "все готово".

Если схематично изобразить алгоритм работы этого кода, то получится что-то такое:
Но если верить этой схеме, время обработки может даже увеличиться за счет всех этих пересылок. Давайте же запустим наш код, и... время обработки выросло на 22.5%!
Так что тут нас настигает следующий момент:

издержки на общение с потоком могут свести на нет весь выигрыш от многопоточности.

Слишком много потоков
Но мы тут все говорим про многопоточность, а поток-то у нас пока всего один! Наверное, нам их просто не хватило, чтобы стало быстрее. Давайте будем создавать на каждую микрозадачу по потоку, передавая ее сразу через workerData - заодно и сэкономим в основном потоке на необходимости дожидаться события 'online' и вызывать worker.postMessage
Сколько-сколько?!.. Да, по времени обработки теперь мы проиграли в 100 раз от первоначального не-многопоточного результата, зато узнали такой принцип:

слишком много одновременно активных потоков жестко конфликтуют за ресурсы (производительность CPU, пропускная способность памяти) и сообща работают намного дольше.

Несколько потоков, Round-robin
То есть потоков нам надо больше одного, но меньше, чем "непонятно сколько". Их количество должно быть таким, чтобы они не конфликтовали за ресурсы, но при этом максимально эффективно использовали их.

Кроме того, раз у нас теперь на каждый поток должна попасть только часть задач (а не все и не одна) ...

необходим алгоритм распределения задач между потоками.

Возьмем в качестве самого простого такого алгоритма Round-robin, когда задачи выдаются потокам последовательно "по кругу".
Поскольку основным используемым ресурсом в нашей задаче у нас является CPU, то сделаем ровно столько вычислительных потоков, сколько у нас CPU-ядер, чтобы в пределе их можно было все загрузить:
Наконец-то мы получили от многопоточности хоть какой-то профит, причем сразу весьма неплохой - на 4-ядерном CPU в 2.5 раза быстрее, чем исходная версия.

"Сколько вешать в граммах?"
Но кто сказал, что активных потоков должно быть ровно столько - не больше и не меньше? Давайте чуть модифицируем наш тест и убедимся сами, заодно получив нагрузку каждого из потоков с помощью worker.eventLoopUtilization:
И вот тут мы можем заметить странность: минимальное время достигнуто при 15 потоках, а вовсе не при 4, что соответствовало бы полной загрузке ядер CPU. Правда, средняя загрузка этих 15 активных потоков при этом была ниже 60%, причем на некоторых - 22%, когда на других - 89%, а ведь это означает, что...

некоторые вычислительные потоки простаивают, если основной поток не успевает давать им задания.

или он отдал это задание не тому, кто был свободен и смог бы выполнить его сразу, а другому потоку, который еще был занят предыдущим заданием.

Как можно разобраться с этими неприятностями - в следующей части.